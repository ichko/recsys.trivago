{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.13.1'"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from tensorflow.keras import layers\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "# tf.enable_eager_execution()\n",
    "tqdm.pandas()\n",
    "pd.set_option('float_format', '{:f}'.format)\n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 36.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df_meta = pd.read_csv('item_metadata.csv', index_col='item_id')\n",
    "df_train = pd.read_csv('train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "112\n",
      "Wall time: 1.38 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "max_meta_len = df_meta['properties'].apply(lambda prop: len(prop.split('|'))).max()\n",
    "print(max_meta_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count   910683.000000\n",
       "mean        17.495651\n",
       "std         48.181687\n",
       "min          1.000000\n",
       "25%          2.000000\n",
       "50%          4.000000\n",
       "75%         13.000000\n",
       "max       3522.000000\n",
       "Name: user_id, dtype: float64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grouped = df_train.groupby(['session_id'])\n",
    "grouped['user_id'].count().describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_seq_len = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FastLabelEncoder:\n",
    "    def __init__(self):\n",
    "        self.token_to_id = dict()\n",
    "        self.id_to_token = dict()\n",
    "        self.unk_id = 1\n",
    "        self.pad_id = 0\n",
    "        self.current_id = 2\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.token_to_id) + 2\n",
    "\n",
    "    def _pad(self, seq, pad):\n",
    "        if pad < 0: return seq\n",
    "        if len(seq) > pad: return seq[:pad]\n",
    "        return seq + [self.pad_id] * (pad - len(seq))\n",
    "\n",
    "    def fit(self, X):\n",
    "        for row in X:\n",
    "            for token in row:\n",
    "                if token not in self.token_to_id:\n",
    "                    self.token_to_id[token] = self.current_id\n",
    "                    self.id_to_token[self.current_id] = token\n",
    "                    self.current_id += 1\n",
    "\n",
    "        return self\n",
    "\n",
    "    def transform(self, X, pad=-1):\n",
    "        return np.array([self._pad([\n",
    "              self.token_to_id[token] if token in self.token_to_id else self.unk_id\n",
    "              for token in row\n",
    "        ], pad) for row in X])\n",
    "        \n",
    "    def fit_transform(self, X, pad=-1):\n",
    "        return self.fit(X).transform(X, pad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ref_vals 36403\n",
      "Wall time: 683 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "ref_vals = df_train[df_train['action_type'].isin([\n",
    "    'search for poi',\n",
    "    'filter selection',\n",
    "    'change of sort order',\n",
    "    'search for destination'\n",
    "])]['reference'].unique()\n",
    "\n",
    "print('ref_vals', len(ref_vals))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "meta_vals 157\n",
      "Wall time: 5.02 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "meta_vals = np.array(list({i for items in df_meta['properties'].apply(lambda x: x.split('|')) for i in items}))\n",
    "\n",
    "print('meta_vals', len(meta_vals))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "action_val_dict 36560\n",
      "Wall time: 62.5 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "action_val_dict = np.array(list(meta_vals) + list(ref_vals))\n",
    "\n",
    "print('action_val_dict', len(action_val_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "action_type_dict 10\n"
     ]
    }
   ],
   "source": [
    "action_type_dict = df_train['action_type'].unique()\n",
    "\n",
    "print('action_type_dict', len(action_type_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0349547ca3074917b8ce62170dbdc856",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1586586), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "846e9a9203604b648035f4def7d9e22f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1586586), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "impr_counter 853540\n",
      "Wall time: 27 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from collections import Counter\n",
    "\n",
    "impr_counter = Counter()\n",
    "\n",
    "def add_to_counter(l):\n",
    "    for i in l:\n",
    "        impr_counter[i] += 1\n",
    "\n",
    "df_train[df_train['action_type'] == 'clickout item']['impressions'].progress_apply(\n",
    "    lambda i: i.split('|')\n",
    ").progress_apply(add_to_counter)\n",
    "\n",
    "print('impr_counter', len(impr_counter))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "impr_dict 100000\n"
     ]
    }
   ],
   "source": [
    "impr_dict = [v[0] for v in impr_counter.most_common(100_000)]\n",
    "\n",
    "print('impr_dict', len(impr_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "impr_seq_len = len(df_train[df_train['action_type'] == 'clickout item']['impressions'].iloc[0].split('|'))\n",
    "impr_seq_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Input:\n",
    "    pad_shapes = {\n",
    "        'type': tf.TensorShape([max_seq_len]),\n",
    "        'value': tf.TensorShape([max_seq_len, max_meta_len]),\n",
    "        'neg': tf.TensorShape([impr_seq_len]),\n",
    "        'pos': tf.TensorShape([])\n",
    "    }\n",
    "    out_shapes = tuple(v for k, v in pad_shapes.items())\n",
    "\n",
    "    def __init__(self):\n",
    "        self.action_types_encoder = FastLabelEncoder().fit([action_type_dict])\n",
    "        self.action_vals_encoder = FastLabelEncoder().fit([action_val_dict])\n",
    "        self.labels_encoder = FastLabelEncoder().fit([impr_dict])\n",
    "        \n",
    "\n",
    "    def generator(self):\n",
    "        last_session_id = None\n",
    "        action_types = []\n",
    "        action_vals = []\n",
    "        MISSING_REF_VAL = '?'\n",
    "\n",
    "        \n",
    "        for _, row in df_train.iterrows(): # tqdm(df_train.iterrows(), total=len(df_train)):\n",
    "            if row['session_id'] != last_session_id:\n",
    "                action_types = []\n",
    "                action_vals = []\n",
    "\n",
    "            action_val = row['reference']\n",
    "\n",
    "            if row['action_type'] != 'clickout item':\n",
    "                action_types.append(row['action_type'])\n",
    "\n",
    "                if action_val.isdigit():\n",
    "                    int_id = int(action_val)\n",
    "                    if int_id in df_meta.index:\n",
    "                        action_vals.append(df_meta.loc[int_id]['properties'].split('|'))\n",
    "                    else:\n",
    "                        action_vals.append([action_val])\n",
    "                else:\n",
    "                    action_vals.append([action_val])\n",
    "                    \n",
    "\n",
    "                if len(action_types) > max_seq_len:\n",
    "                    action_types.pop(0)\n",
    "                    action_vals.pop(0)\n",
    "            elif len(action_types) > 0:\n",
    "                neg = [i for i in row['impressions'].split('|') if i != action_val]\n",
    "                output = self.action_types_encoder.transform([action_types])[0], \\\n",
    "                         self.action_vals_encoder.transform(action_vals, pad=max_meta_len), \\\n",
    "                         self.labels_encoder.transform([neg])[0], \\\n",
    "                         self.labels_encoder.transform([[action_val]])[0][0]\n",
    "                \n",
    "                yield output\n",
    "\n",
    "            last_session_id = row['session_id']\n",
    "\n",
    "    def as_dataset(self, batch_size):\n",
    "        dataset = tf.data.Dataset.from_generator(\n",
    "            self.generator,\n",
    "            (tf.int32,) * 4,\n",
    "            (\n",
    "                tf.TensorShape([None]),\n",
    "                tf.TensorShape([None, None]),\n",
    "                tf.TensorShape([None]),\n",
    "                tf.TensorShape([])\n",
    "            )\n",
    "        )\n",
    "\n",
    "        dataset = dataset.padded_batch(batch_size, padded_shapes=self.out_shapes).repeat()\n",
    "\n",
    "        return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [],
   "source": [
    "# next(Input().generator())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# i = Input().generator()\n",
    "# next(i)\n",
    "# for _ in range(5000):\n",
    "#     next(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "too slow \n",
    "\n",
    "https://stackoverflow.com/questions/24870953/does-pandas-iterrows-have-performance-issues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 114 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor 'IteratorGetNext_11:0' shape=(?, 100) dtype=int32>,\n",
       " <tf.Tensor 'IteratorGetNext_11:1' shape=(?, 100, 112) dtype=int32>,\n",
       " <tf.Tensor 'IteratorGetNext_11:2' shape=(?, 25) dtype=int32>,\n",
       " <tf.Tensor 'IteratorGetNext_11:3' shape=(?,) dtype=int32>)"
      ]
     },
     "execution_count": 247,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "Input().as_dataset(batch_size=3).make_one_shot_iterator().get_next()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [],
   "source": [
    "import SASRec.modules as sas_module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [],
   "source": [
    "inp = Input()\n",
    "dataset = inp.as_dataset(batch_size=3)\n",
    "\n",
    "def mk_model():\n",
    "    action_type_emb_size = 20\n",
    "    action_val_emb_size = 20\n",
    "    output_emb_size = 20\n",
    "    \n",
    "    type_input = layers.Input(shape=Input.pad_shapes['type'])\n",
    "    value_input = layers.Input(shape=Input.pad_shapes['value'])\n",
    "    pos_input = layers.Input(shape=Input.pad_shapes['pos'])\n",
    "    neg_input = layers.Input(shape=Input.pad_shapes['neg'])\n",
    "\n",
    "    action_type = layers.Embedding(\n",
    "        input_dim=len(inp.action_types_encoder),\n",
    "        output_dim=action_type_emb_size,\n",
    "        mask_zero=True\n",
    "    )(type_input)\n",
    "\n",
    "    action_val = layers.Embedding(\n",
    "        input_dim=len(inp.action_vals_encoder),\n",
    "        output_dim=action_val_emb_size,\n",
    "        mask_zero=True\n",
    "    )(value_input)\n",
    "\n",
    "    pos = layers.Embedding(\n",
    "        input_dim=len(inp.labels_encoder),\n",
    "        output_dim=output_emb_size,\n",
    "        mask_zero=True\n",
    "    )(pos_input)\n",
    "\n",
    "    neg = layers.Embedding(\n",
    "        input_dim=len(inp.labels_encoder),\n",
    "        output_dim=output_emb_size,\n",
    "        mask_zero=True\n",
    "    )(neg_input)\n",
    "\n",
    "    dimension_of_seq_features = 2\n",
    "    action_val_reduced = tf.reduce_mean(action_val, dimension_of_seq_features)\n",
    "\n",
    "    seq = (action_type + action_val_reduced) / 2\n",
    "\n",
    "    # (batch, sequence, embedding)\n",
    "    # seq, pos, neg\n",
    "    # (<tf.Tensor 'Reshape_3:0' shape=(?, 1000) dtype=float32>,\n",
    "    #  <tf.Tensor 'embedding_lookup_22/Identity_2:0' shape=(?, 20) dtype=float32>,\n",
    "    #  <tf.Tensor 'Mean_6:0' shape=(?, 20) dtype=float32>)\n",
    "\n",
    "    num_blocks = 2\n",
    "    hidden_units = output_emb_size\n",
    "    num_heads = 2\n",
    "    dropout_rate = 0.5\n",
    "    is_training = True\n",
    "\n",
    "    mask = tf.to_float(tf.not_equal(seq, 0))\n",
    "\n",
    "    for i in range(num_blocks):\n",
    "        with tf.variable_scope('num_blocks_%d' % i):\n",
    "            # self-attention\n",
    "            seq = sas_module.multihead_attention(\n",
    "                queries=sas_module.normalize(seq),\n",
    "                keys=seq,\n",
    "                num_units=hidden_units,\n",
    "                num_heads=num_heads,\n",
    "                dropout_rate=dropout_rate,\n",
    "                is_training=is_training,\n",
    "                causality=True,\n",
    "                scope='self_attention'\n",
    "            )\n",
    "\n",
    "            # Feed forward\n",
    "            seq = sas_module.feedforward(\n",
    "                sas_module.normalize(seq),\n",
    "                num_units=[hidden_units, hidden_units],\n",
    "                dropout_rate=dropout_rate,\n",
    "                is_training=is_training\n",
    "            )\n",
    "\n",
    "            seq *= mask\n",
    "\n",
    "    seq = sas_module.normalize(seq)\n",
    "    \n",
    "    seq = tf.reshape(seq, [tf.shape(seq)[0], max_seq_len * output_emb_size])\n",
    "    neg_emb = tf.reduce_mean(neg, 1)\n",
    "    pos_emb = pos\n",
    "\n",
    "    seq_logits = tf.keras.layers.Dense(pos.shape[1].value)(seq)\n",
    "    pos_logits = tf.reduce_sum(pos_emb * seq_logits, -1)\n",
    "    neg_logits = tf.reduce_sum(neg_emb * seq_logits, -1)\n",
    "    \n",
    "    loss = tf.reduce_sum(\n",
    "        - tf.log(tf.sigmoid(pos_logits) + 1e-24)\n",
    "        - tf.log(1 - tf.sigmoid(neg_logits) + 1e-24)\n",
    "    )\n",
    "    \n",
    "    reg_losses = tf.get_collection(tf.GraphKeys.REGULARIZATION_LOSSES)\n",
    "    loss += sum(reg_losses)\n",
    "    \n",
    "    tf.summary.scalar('loss', loss)\n",
    "    \n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate=0.001, beta2=0.98).minimize(loss)\n",
    "    \n",
    "    return type_input, value_input, pos_input, neg_input, loss, optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b4f2dbb1cd304091966c9adfaf73cff7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# 0 704.35315\n",
      "# 10 712.4947\n",
      "# 20 716.7414\n",
      "# 30 701.52844\n",
      "# 40 709.5875\n",
      "# 50 713.99927\n"
     ]
    }
   ],
   "source": [
    "with tf.Graph().as_default():\n",
    "    with tf.Session() as sess:\n",
    "        type_input, value_input, pos_input, neg_input, loss, optimizer = mk_model()\n",
    "        iterator = inp.as_dataset(batch_size=512).make_one_shot_iterator()\n",
    "        t, v, n, p = iterator.get_next()\n",
    "\n",
    "        for i in tqdm(range(1000)):\n",
    "            t_val = t.eval(session=sess)\n",
    "            v_val = v.eval(session=sess)\n",
    "            n_val = n.eval(session=sess)\n",
    "            p_val = p.eval(session=sess)\n",
    "\n",
    "            sess.run(tf.global_variables_initializer())\n",
    "            cost, _ = sess.run(\n",
    "                [loss, optimizer],\n",
    "                {type_input: t_val, value_input: v_val, pos_input: p_val, neg_input: n_val}\n",
    "            )\n",
    "            \n",
    "            if i % 10 == 0:\n",
    "                print('#', i, cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.utils.plot_model(model, show_shapes=True, show_layer_names=True, to_file='model.png')\n",
    "from IPython.display import Image\n",
    "Image(retina=True, filename='model.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
