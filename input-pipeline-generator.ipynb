{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.13.1'"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "tf.enable_eager_execution()\n",
    "pd.set_option('float_format', '{:f}'.format)\n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 42.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df_meta = pd.read_csv('item_metadata.csv', index_col='item_id')\n",
    "df_train = pd.read_csv('train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1.41 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "max_meta_len = df_meta['properties'].apply(lambda prop: len(prop.split('|'))).max()\n",
    "max_meta_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FastLabelEncoder:\n",
    "    def __init__(self):\n",
    "        self.token_to_id = dict()\n",
    "        self.id_to_token = dict()\n",
    "        self.unk_id = 1\n",
    "        self.pad_id = 0\n",
    "        self.current_id = 2\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.token_to_id)\n",
    "\n",
    "    def _pad(self, seq, pad):\n",
    "        if pad < 0: return seq\n",
    "        if len(seq) > pad: return seq[:pad]\n",
    "        return seq + [self.pad_id] * (pad - len(seq))\n",
    "\n",
    "    def fit(self, X):\n",
    "        for row in X:\n",
    "            for token in row:\n",
    "                if token not in self.token_to_id:\n",
    "                    self.token_to_id[token] = self.current_id\n",
    "                    self.id_to_token[self.current_id] = token\n",
    "                    self.current_id += 1\n",
    "\n",
    "        return self\n",
    "\n",
    "    def transform(self, X, pad=-1):\n",
    "        return np.array([self._pad([\n",
    "              self.token_to_id[token] if token in self.token_to_id else self.unk_id\n",
    "              for token in row\n",
    "        ], pad) for row in X])\n",
    "        \n",
    "    def fit_transform(self, X, pad=-1):\n",
    "        return self.fit(X).transform(X, pad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Input:\n",
    "    col_shapes = {\n",
    "        'type': tf.TensorShape([None]),\n",
    "        'value': tf.TensorShape([None, max_meta_len]),\n",
    "        'neg': tf.TensorShape([None]),\n",
    "        'pos': tf.TensorShape([])\n",
    "    }\n",
    "    out_shapes = tuple(v for k, v in col_shapes.items())\n",
    "\n",
    "    def __init__(self):\n",
    "        self.action_types_encoder = FastLabelEncoder()\n",
    "        self.action_vals_encoder = FastLabelEncoder()\n",
    "        self.labels_encoder = FastLabelEncoder()\n",
    "\n",
    "    def generator(self):\n",
    "        last_session_id = None\n",
    "        action_types = []\n",
    "        action_vals = []\n",
    "        MISSING_REF_VAL = '?'\n",
    "\n",
    "        for _, row in df_train.iterrows():\n",
    "            if row['session_id'] != last_session_id:\n",
    "                action_types = []\n",
    "                action_vals = []\n",
    "\n",
    "            action_val = row['reference']\n",
    "\n",
    "            if row['action_type'] != 'clickout item':\n",
    "                action_types.append(row['action_type'])\n",
    "\n",
    "                if action_val.isdigit():\n",
    "                    int_id = int(action_val)\n",
    "                    if int_id in df_meta.index:\n",
    "                        action_vals.append(df_meta.loc[int_id]['properties'].split('|'))\n",
    "                    else:\n",
    "                        action_vals.append([int_id])\n",
    "                else:\n",
    "                    action_vals.append([action_val])\n",
    "            else:\n",
    "                neg = [int(i) for i in row['impressions'].split('|') if i != action_val]\n",
    "                yield self.action_types_encoder.fit_transform([action_types])[0], \\\n",
    "                      self.action_vals_encoder.fit_transform(action_vals, pad=max_meta_len), \\\n",
    "                      self.labels_encoder.fit_transform([neg])[0], \\\n",
    "                      self.labels_encoder.fit_transform([[int(action_val)]])[0][0]\n",
    "\n",
    "            last_session_id = row['session_id']\n",
    "\n",
    "    def as_dataset(self, batch_size):\n",
    "        dataset = tf.data.Dataset.from_generator(\n",
    "            self.generator,\n",
    "            (tf.int32,) * 4,\n",
    "            self.out_shapes\n",
    "        )\n",
    "\n",
    "        dataset = dataset.padded_batch(batch_size, padded_shapes=self.out_shapes)\n",
    "\n",
    "        return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3]),\n",
       " array([[ 2,  0,  0, ...,  0,  0,  0],\n",
       "        [ 3,  4,  5, ...,  0,  0,  0],\n",
       "        [ 3,  4,  5, ...,  0,  0,  0],\n",
       "        ...,\n",
       "        [28, 29, 30, ...,  0,  0,  0],\n",
       "        [28, 29, 30, ...,  0,  0,  0],\n",
       "        [28, 29, 30, ...,  0,  0,  0]]),\n",
       " array([ 2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17, 18,\n",
       "        19, 20, 21, 22, 23, 24, 25]),\n",
       " 26)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(Input().generator())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 13.8 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "i = Input().generator()\n",
    "next(i)\n",
    "for _ in range(5000):\n",
    "    next(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "too slow \n",
    "\n",
    "https://stackoverflow.com/questions/24870953/does-pandas-iterrows-have-performance-issues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "inp = Input()\n",
    "dataset = inp.as_dataset(batch_size=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: id=4017, shape=(3, 34), dtype=int32, numpy=\n",
       " array([[2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
       "         3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 4]])>,\n",
       " <tf.Tensor: id=4018, shape=(3, 34, 112), dtype=int32, numpy=\n",
       " array([[[ 2,  0,  0, ...,  0,  0,  0],\n",
       "         [ 3,  4,  5, ...,  0,  0,  0],\n",
       "         [ 3,  4,  5, ...,  0,  0,  0],\n",
       "         ...,\n",
       "         [ 0,  0,  0, ...,  0,  0,  0],\n",
       "         [ 0,  0,  0, ...,  0,  0,  0],\n",
       "         [ 0,  0,  0, ...,  0,  0,  0]],\n",
       " \n",
       "        [[ 2,  0,  0, ...,  0,  0,  0],\n",
       "         [ 3,  4,  5, ...,  0,  0,  0],\n",
       "         [ 3,  4,  5, ...,  0,  0,  0],\n",
       "         ...,\n",
       "         [ 0,  0,  0, ...,  0,  0,  0],\n",
       "         [ 0,  0,  0, ...,  0,  0,  0],\n",
       "         [ 0,  0,  0, ...,  0,  0,  0]],\n",
       " \n",
       "        [[54, 66, 67, ...,  0,  0,  0],\n",
       "         [54, 66, 67, ...,  0,  0,  0],\n",
       "         [54, 66, 67, ...,  0,  0,  0],\n",
       "         ...,\n",
       "         [54, 66, 67, ...,  0,  0,  0],\n",
       "         [54, 66, 67, ...,  0,  0,  0],\n",
       "         [54, 66, 67, ...,  0,  0,  0]]])>,\n",
       " <tf.Tensor: id=4019, shape=(3, 24), dtype=int32, numpy=\n",
       " array([[ 2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
       "         18, 19, 20, 21, 22, 23, 24, 25],\n",
       "        [27, 14, 28, 29, 30, 31, 22, 32,  7,  8, 23, 33, 12, 34, 35, 36,\n",
       "         19, 37, 38, 39, 40, 41, 42, 20],\n",
       "        [43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58,\n",
       "         59, 60, 61, 62, 63, 64, 65, 66]])>,\n",
       " <tf.Tensor: id=4020, shape=(3,), dtype=int32, numpy=array([26, 24, 67])>)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.make_one_shot_iterator().get_next()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "action_type_emb_size = 20\n",
    "action_val_emb_size = 20\n",
    "output_emb_size = 20\n",
    "\n",
    "action_type = layers.Embedding(\n",
    "    input_dim=len(inp.action_types_encoder),\n",
    "    output_dim=action_type_emb_size,\n",
    "    mask_zero=True\n",
    ")(layers.Input(shape=Input.col_shapes['type']))\n",
    "\n",
    "action_val = layers.Embedding(\n",
    "    input_dim=len(inp.action_vals_encoder),\n",
    "    output_dim=action_val_emb_size,\n",
    "    mask_zero=True\n",
    ")(layers.Input(shape=Input.col_shapes['value']))\n",
    "\n",
    "pos = layers.Embedding(\n",
    "    input_dim=len(inp.labels_encoder),\n",
    "    output_dim=output_emb_size,\n",
    "    mask_zero=True\n",
    ")(layers.Input(shape=Input.col_shapes['pos']))\n",
    "\n",
    "neg = layers.Embedding(\n",
    "    input_dim=len(inp.labels_encoder),\n",
    "    output_dim=output_emb_size,\n",
    "    mask_zero=True\n",
    ")(layers.Input(shape=Input.col_shapes['neg']))\n",
    "\n",
    "dimension_of_seq_features = 2\n",
    "action_val_reduced = tf.reduce_mean(action_val, dimension_of_seq_features)\n",
    "\n",
    "seq = layers.Concatenate(axis=2)([action_type, action_val_reduced])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor 'concat_12:0' shape=(?, ?, 40) dtype=float32>,\n",
       " <tf.Tensor 'embedding_lookup_22/Identity_2:0' shape=(?, 20) dtype=float32>,\n",
       " <tf.Tensor 'embedding_lookup_23/Identity_2:0' shape=(?, ?, 20) dtype=float32>)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# (batch, sequence, embedding of items in sequence)\n",
    "seq, pos, neg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "import SASRec.modules as sas_module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_blocks = 2\n",
    "hidden_units = 40\n",
    "num_heads = 1\n",
    "dropout_rate = 0.5\n",
    "is_training = True\n",
    "max_seq_len = 500\n",
    "\n",
    "mask = tf.to_float(tf.not_equal(seq, 0))\n",
    "\n",
    "for i in range(num_blocks):\n",
    "    with tf.variable_scope('num_blocks_%d' % i):\n",
    "        # self-attention\n",
    "#         seq = sas_module.multihead_attention(\n",
    "#             queries=sas_module.normalize(seq),\n",
    "#             keys=seq,\n",
    "#             num_units=hidden_units,\n",
    "#             num_heads=num_heads,\n",
    "#             dropout_rate=dropout_rate,\n",
    "#             is_training=is_training,\n",
    "#             causality=True,\n",
    "#             scope='self_attention'\n",
    "#         )\n",
    "\n",
    "        # Feed forward\n",
    "        seq = sas_module.feedforward(\n",
    "            sas_module.normalize(seq),\n",
    "            num_units=[hidden_units, hidden_units],\n",
    "            dropout_rate=dropout_rate,\n",
    "            is_training=is_training\n",
    "        )\n",
    "\n",
    "        seq *= mask\n",
    "\n",
    "seq = sas_module.normalize(seq)\n",
    "\n",
    "# self.pos_logits = tf.reduce_sum(pos_emb * seq, -1)\n",
    "# self.neg_logits = tf.reduce_sum(neg_emb * seq, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = layers.Bidirectional(\n",
    "    layers.LSTM(128, dropout=0.25, return_sequences=False, recurrent_dropout=0.1)\n",
    ")(seq)\n",
    "\n",
    "model = layers.Dense(units=1)(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "Failed to import pydot. You must install pydot and graphviz for `pydotprint` to work.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvocationException\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\utils\\vis_utils.py\u001b[0m in \u001b[0;36m_check_pydot\u001b[1;34m()\u001b[0m\n\u001b[0;32m     44\u001b[0m     \u001b[1;31m# to check the pydot/graphviz installation.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 45\u001b[1;33m     \u001b[0mpydot\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDot\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcreate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpydot\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     46\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pydot_ng\\__init__.py\u001b[0m in \u001b[0;36mcreate\u001b[1;34m(self, prog, format)\u001b[0m\n\u001b[0;32m   1820\u001b[0m                 raise InvocationException(\n\u001b[1;32m-> 1821\u001b[1;33m                     'GraphViz\\'s executables not found')\n\u001b[0m\u001b[0;32m   1822\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mInvocationException\u001b[0m: GraphViz's executables not found",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-29-9c82bc209b40>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshow_shapes\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshow_layer_names\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mto_file\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'model.png'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mIPython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdisplay\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mImage\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mImage\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mretina\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'model.png'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\utils\\vis_utils.py\u001b[0m in \u001b[0;36mplot_model\u001b[1;34m(model, to_file, show_shapes, show_layer_names, rankdir)\u001b[0m\n\u001b[0;32m    146\u001b[0m           \u001b[1;34m'LR'\u001b[0m \u001b[0mcreates\u001b[0m \u001b[0ma\u001b[0m \u001b[0mhorizontal\u001b[0m \u001b[0mplot\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    147\u001b[0m   \"\"\"\n\u001b[1;32m--> 148\u001b[1;33m   \u001b[0mdot\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel_to_dot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshow_shapes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshow_layer_names\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrankdir\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    149\u001b[0m   \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mextension\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplitext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mto_file\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    150\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mextension\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\utils\\vis_utils.py\u001b[0m in \u001b[0;36mmodel_to_dot\u001b[1;34m(model, show_shapes, show_layer_names, rankdir)\u001b[0m\n\u001b[0;32m     69\u001b[0m   \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mSequential\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     70\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 71\u001b[1;33m   \u001b[0m_check_pydot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     72\u001b[0m   \u001b[0mdot\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpydot\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     73\u001b[0m   \u001b[0mdot\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'rankdir'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrankdir\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\utils\\vis_utils.py\u001b[0m in \u001b[0;36m_check_pydot\u001b[1;34m()\u001b[0m\n\u001b[0;32m     47\u001b[0m     \u001b[1;31m# pydot raises a generic Exception here,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     48\u001b[0m     \u001b[1;31m# so no specific class can be caught.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 49\u001b[1;33m     raise ImportError('Failed to import pydot. You must install pydot'\n\u001b[0m\u001b[0;32m     50\u001b[0m                       ' and graphviz for `pydotprint` to work.')\n\u001b[0;32m     51\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mImportError\u001b[0m: Failed to import pydot. You must install pydot and graphviz for `pydotprint` to work."
     ]
    }
   ],
   "source": [
    "tf.keras.utils.plot_model(model, show_shapes=True, show_layer_names=True, to_file='model.png')\n",
    "from IPython.display import Image\n",
    "Image(retina=True, filename='model.png')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
